{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5 import explain_prediction\n",
    "import shap\n",
    "from sklearn.metrics import precision_score, roc_curve, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from hhh import summary_legacy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "def dataprocessing(data):\n",
    "    dummies_Sex = pd.get_dummies(data['Sex'], prefix='Sex')\n",
    "    dummies_Sex = pd.DataFrame(dummies_Sex)\n",
    "    \n",
    "    ECOG = {'ECOG 0': 0, 'ECOG 1': 1, 'ECOG 2': 2, 'ECOG 3': 3, 'ECOG 4': 4}\n",
    "    data[\"ECOG_Performance\"] = data[\"ECOG_Performance\"].map(ECOG)\n",
    "    \n",
    "    smoker = {'Non-smoker': 0, 'Ex-smoker': 1, 'Current': 2}\n",
    "    data[\"Smoking\"] = data[\"Smoking\"].map(smoker)\n",
    "    \n",
    "    drinker = {'non-drinker': 0, 'light': 1, 'Moderate': 2, 'ex-drinker': 3, 'heavy': 4, 'unknown': 5}\n",
    "    data[\"Drinking\"] = data[\"Drinking\"].map(drinker)\n",
    "    \n",
    "    sub = {'post wall': 1, 'Tonsillar Fossa': 2, 'Base of Tongue': 3, 'Tonsil ': 4,\n",
    "           'Tonsil Pillar ': 5, 'Soft Palate ': 6, 'Vallecula': 7, 'lat wall': 0}\n",
    "    data[\"Subsite\"] = data[\"Subsite\"].map(sub)\n",
    "    \n",
    "    T = {'T1': 1, 'T2': 2, 'T3': 3, 'T3 (2) ': 4, 'T4a': 5, 'T4b': 0}\n",
    "    data[\"T\"] = data[\"T\"].map(T)\n",
    "    \n",
    "    N = {'N0': 0, 'N1': 1, 'N2a': 2, 'N2b': 3, 'N2c': 4, 'N3': 5}\n",
    "    data[\"N\"] = data[\"N\"].map(N)\n",
    "    \n",
    "    M = {'M0': 0}\n",
    "    data[\"M\"] = data[\"M\"].map(M)\n",
    "    \n",
    "    stage = {'I': 0, 'II': 1, 'III': 2, 'IVA': 3, 'IVB': 4}\n",
    "    data[\"Stage\"] = data[\"Stage\"].map(stage)\n",
    "    \n",
    "    Hpv = {'  Negative': 0, '  positive': 1}\n",
    "    data[\"HPVp16status\"] = data[\"HPVp16status\"].map(Hpv)\n",
    "    \n",
    "    Che = {'none': 0, 'Yes': 1}\n",
    "    data[\"Chemotherapy\"] = data[\"Chemotherapy\"].map(Che)\n",
    "    \n",
    "    RT = {'IMRT': 0, 'IMRT-ipsilat': 1}\n",
    "    data[\"RT_Tech\"] = data[\"RT_Tech\"].map(RT)\n",
    "    \n",
    "    Status = {'Dead': 1, 'Alive': 0}\n",
    "    data[\"Status\"] = data[\"Status\"].map(Status)\n",
    "    \n",
    "    data.drop(['PatientID', 'Sex','Ds_Site', 'Path', 'Primary_Treatment', 'Cause_of_Death',\n",
    "               'Local_Failure', 'local_failure(days)', 'Regional_Failure', 'regional_failure(days)',\n",
    "               'Distant_Failure', 'distant_failure (days)', 'Second_Primary', '2nd_cancer_(days)',\n",
    "               'PMID', 'diagnostics_Versions_PyRadiomics', 'diagnostics_Versions_Numpy',\n",
    "               'diagnostics_Versions_SimpleITK', 'diagnostics_Versions_PyWavelet', 'diagnostics_Versions_Python',\n",
    "               'diagnostics_Configuration_Settings', 'diagnostics_Configuration_EnabledImageTypes',\n",
    "               'diagnostics_Image-original_Hash', 'diagnostics_Image-original_Dimensionality',\n",
    "               'diagnostics_Image-original_Spacing', 'diagnostics_Image-original_Size',\n",
    "               'diagnostics_Image-original_Mean',\n",
    "               'diagnostics_Image-original_Minimum', 'diagnostics_Image-original_Maximum',\n",
    "               'diagnostics_Mask-original_Hash', 'diagnostics_Mask-original_Spacing',\n",
    "               'diagnostics_Mask-original_Size',\n",
    "               'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_VoxelNum',\n",
    "               'diagnostics_Mask-original_VolumeNum', 'diagnostics_Mask-original_CenterOfMassIndex',\n",
    "               'diagnostics_Mask-original_CenterOfMass'\n",
    "\n",
    "               ], axis=1, inplace=True)\n",
    "    \n",
    "    data_df=pd.concat([data,dummies_Sex],axis=1)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理训练数据\n",
    "train_data = 'train_data.csv'\n",
    "data_train = pd.read_csv(train_data)\n",
    "dataprocessing(data_train)\n",
    "data_train = data_train.fillna(0)\n",
    "\n",
    "#标准化\n",
    "Train_X = data_train.drop(['FU','Status'],axis=1)\n",
    "#Train_X = data_train.drop(['Status'],axis=1)\n",
    "Train_y = data_train.pop('FU').values\n",
    "colNames = Train_X.columns\n",
    "\n",
    "stdScale = StandardScaler().fit(Train_X) ## 生成规则\n",
    "Train_X = stdScale.transform(Train_X) ## 将规则应用于训练集\n",
    "\n",
    "Train_X=pd.DataFrame(Train_X)\n",
    "Train_X.columns=colNames\n",
    "# print(z_status)\n",
    "X_train_lifetime, X_test_lifetime, y_train_lifetime, y_test_lifetime = train_test_split(Train_X, Train_y, test_size=0.3)\n",
    "# X_train_status, X_test_status, y_train_status, y_test_status = train_test_split(X_status, y_status, test_size=0.3)\n",
    "# print(Train_X)\n",
    "shit = pd.DataFrame()\n",
    "fuck =Train_X.columns\n",
    "for x in fuck:\n",
    "    shit[x]=Train_X[x]\n",
    "# shit['ECOG_Performance']=Train_X['ECOG_Performance']\n",
    "# print(shit.head())\n",
    "# print(Train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "#训练XGboost\n",
    "#回归\n",
    "model_xgb = xgb.XGBRegressor(max_depth=3, learning_rate=0.1, n_estimators=100)\n",
    "model_xgb.fit(X_train_lifetime, y_train_lifetime)\n",
    "\n",
    "preds_test = model_xgb.predict(X_test_lifetime)\n",
    "#分类\n",
    "# model_xgb =  xgb.XGBClassifier()\n",
    "# model_xgb.fit(X_train_status, y_train_status)\n",
    "\n",
    "# train_pre_status = model_xgb.predict(X_train_status)\n",
    "# test_pre_status = model_xgb.predict(X_test_status)\n",
    "\n",
    "# # train_pre_proba = model_xgb.predict_proba(X_train_status)\n",
    "# test_pre_proba = model_xgb.predict_proba(X_test_status)\n",
    "\n",
    "# # train_auc = roc_auc_score(y_train_status, train_pre_status)\n",
    "# test_auc = roc_auc_score(y_test_status, test_pre_status)\n",
    "\n",
    "#roc曲线\n",
    "# Xgbc_fpr,Xgbc_tpr,Xgbc_threasholds=roc_curve(y_test_status,test_pre_proba[:,1]) # 计算ROC的值,svm_threasholds为阈值\n",
    "# plt.title(\"roc_curve of %s(AUC=%.4f)\" %('Xgbc_test',test_auc))\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.plot(Xgbc_fpr,Xgbc_tpr)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "#训练svr\n",
    "# linear_svr = SVR(kernel='rbf', C=100, gamma=0.0001)\n",
    "# linear_svr.fit(X_train_lifetime, y_train_lifetime)\n",
    "# preds_test = linear_svr.predict(X_test_lifetime)\n",
    "#print(preds_test)\n",
    "print(\"--------------------------------\")\n",
    "# print(preds_test)\n",
    "#回归评估\n",
    "# print(preds_test)\n",
    "# print(\"------------------------------------\")\n",
    "# print(y_test_lifetime)\n",
    "# print(\"rScore:\")\n",
    "# print(metrics.r2_score(y_test_lifetime, preds_test))\n",
    "# print(\"mse:\")\n",
    "# print(mean_squared_error(y_test_lifetime, preds_test))\n",
    "# print(\"mae:\")\n",
    "# print(mean_absolute_error(y_test_lifetime, preds_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#置换特征重要性\n",
    "# perm = PermutationImportance(model_xgb, random_state=1).fit(X_test_lifetime, y_test_lifetime)\n",
    "# eli5.show_weights(perm, feature_names=X_test_lifetime.columns.tolist(),top=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-af65e917db80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Treeshap解释\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitjs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mshap_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_lifetime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shap' is not defined"
     ]
    }
   ],
   "source": [
    "#Treeshap解释\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model_xgb)\n",
    "shap_values = explainer.shap_values(X_test_lifetime)\n",
    "print(shap_values.shape)\n",
    "# shap.plots.force(explainer.expected_value, shap_values[1],X_test_lifetime.columns)\n",
    "# shap.summary_plot(shap_values, X_test_lifetime,max_display=20)\n",
    "shap.summary_plot(shap_values,X_test_lifetime.columns,plot_type=\"bar\",max_display=10)\n",
    "# summary_legacy(shap_values,X_test_lifetime.columns,max_display=10)\n",
    "#xgb.plot_importance(model_xgb,max_num_features=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:shit]",
   "language": "python",
   "name": "conda-env-shit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
