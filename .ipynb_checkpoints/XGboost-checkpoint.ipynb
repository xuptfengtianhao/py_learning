{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5 import explain_prediction\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "def dataprocessing(data):\n",
    "    dummies_Sex = pd.get_dummies(data['Sex'], prefix='Sex')\n",
    "    dummies_Sex = pd.DataFrame(dummies_Sex)\n",
    "    \n",
    "    ECOG = {'ECOG 0': 0, 'ECOG 1': 1, 'ECOG 2': 2, 'ECOG 3': 3, 'ECOG 4': 4}\n",
    "    data[\"ECOG_Performance\"] = data[\"ECOG_Performance\"].map(ECOG)\n",
    "    \n",
    "    smoker = {'Non-smoker': 0, 'Ex-smoker': 1, 'Current': 2}\n",
    "    data[\"Smoking\"] = data[\"Smoking\"].map(smoker)\n",
    "    \n",
    "    drinker = {'non-drinker': 0, 'light': 1, 'Moderate': 2, 'ex-drinker': 3, 'heavy': 4, 'unknown': 5}\n",
    "    data[\"Drinking\"] = data[\"Drinking\"].map(drinker)\n",
    "    \n",
    "    sub = {'post wall': 1, 'Tonsillar Fossa': 2, 'Base of Tongue': 3, 'Tonsil ': 4,\n",
    "           'Tonsil Pillar ': 5, 'Soft Palate ': 6, 'Vallecula': 7, 'lat wall': 0}\n",
    "    data[\"Subsite\"] = data[\"Subsite\"].map(sub)\n",
    "    \n",
    "    T = {'T1': 1, 'T2': 2, 'T3': 3, 'T3 (2) ': 4, 'T4a': 5, 'T4b': 0}\n",
    "    data[\"T\"] = data[\"T\"].map(T)\n",
    "    \n",
    "    N = {'N0': 0, 'N1': 1, 'N2a': 2, 'N2b': 3, 'N2c': 4, 'N3': 5}\n",
    "    data[\"N\"] = data[\"N\"].map(N)\n",
    "    \n",
    "    M = {'M0': 0}\n",
    "    data[\"M\"] = data[\"M\"].map(M)\n",
    "    \n",
    "    stage = {'I': 0, 'II': 1, 'III': 2, 'IVA': 3, 'IVB': 4}\n",
    "    data[\"Stage\"] = data[\"Stage\"].map(stage)\n",
    "    \n",
    "    Hpv = {'  Negative': 0, '  positive': 1}\n",
    "    data[\"HPVp16status\"] = data[\"HPVp16status\"].map(Hpv)\n",
    "    \n",
    "    Che = {'none': 0, 'Yes': 1}\n",
    "    data[\"Chemotherapy\"] = data[\"Chemotherapy\"].map(Che)\n",
    "    \n",
    "    RT = {'IMRT': 0, 'IMRT-ipsilat': 1}\n",
    "    data[\"RT_Tech\"] = data[\"RT_Tech\"].map(RT)\n",
    "    \n",
    "    Status = {'Dead': 1, 'Alive': 0}\n",
    "    data[\"Status\"] = data[\"Status\"].map(Status)\n",
    "    \n",
    "    data.drop(['PatientID', 'Sex','Ds_Site', 'Path', 'Primary_Treatment', 'Cause_of_Death',\n",
    "               'Local_Failure', 'local_failure(days)', 'Regional_Failure', 'regional_failure(days)',\n",
    "               'Distant_Failure', 'distant_failure (days)', 'Second_Primary', '2nd_cancer_(days)',\n",
    "               'PMID', 'diagnostics_Versions_PyRadiomics', 'diagnostics_Versions_Numpy',\n",
    "               'diagnostics_Versions_SimpleITK', 'diagnostics_Versions_PyWavelet', 'diagnostics_Versions_Python',\n",
    "               'diagnostics_Configuration_Settings', 'diagnostics_Configuration_EnabledImageTypes',\n",
    "               'diagnostics_Image-original_Hash', 'diagnostics_Image-original_Dimensionality',\n",
    "               'diagnostics_Image-original_Spacing', 'diagnostics_Image-original_Size',\n",
    "               'diagnostics_Image-original_Mean',\n",
    "               'diagnostics_Image-original_Minimum', 'diagnostics_Image-original_Maximum',\n",
    "               'diagnostics_Mask-original_Hash', 'diagnostics_Mask-original_Spacing',\n",
    "               'diagnostics_Mask-original_Size',\n",
    "               'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_VoxelNum',\n",
    "               'diagnostics_Mask-original_VolumeNum', 'diagnostics_Mask-original_CenterOfMassIndex',\n",
    "               'diagnostics_Mask-original_CenterOfMass'\n",
    "\n",
    "               ], axis=1, inplace=True)\n",
    "    \n",
    "    data_df=pd.concat([data,dummies_Sex],axis=1)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标准化\n",
    "def standerscaler(df):\n",
    "    X = df.drop(['FU', 'Status'], axis=1)\n",
    "    y = df.pop('Status').values\n",
    "    z = df.pop('FU').values\n",
    "\n",
    "    # print(X_status)\n",
    "    # print(y_status)\n",
    "    colNames = X.columns\n",
    "    X = X.astype(np.float64)\n",
    "    y=y.astype(np.float64)\n",
    "    z=z.astype(np.float64)\n",
    "\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X = pd.DataFrame(X)\n",
    "    X.columns = colNames\n",
    "    return X, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (27) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "train_data = 'train_data.csv'\n",
    "data_train = pd.read_csv(train_data)\n",
    "#print(data_train)\n",
    "dataprocessing(data_train)\n",
    "# print(\"------------------------------------------------\")\n",
    "df = data_train.fillna(0)\n",
    "print(\"----------------------------------------\")\n",
    "X_status, y_status, z_status = standerscaler(df)\n",
    "X_fu = X_status\n",
    "z_fu = z_status\n",
    "X_train_lifetime, X_test_lifetime, y_train_lifetime, y_test_lifetime = train_test_split(X_status, z_status, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2217.0686  2269.0115  2218.5657   817.3191  1937.7062  2699.697\n",
      " 2593.8884  3139.3926  2599.6743  1167.7458  1069.9774  1583.7584\n",
      " 2709.2805  2853.7375  2158.0789  1761.2373  2811.3232  2237.283\n",
      " 1053.7239  2499.7664  1663.391    526.71204 2825.4268  1718.6898\n",
      " 2492.7686  1902.2019  2342.134    744.08075 1708.5488  2729.2703\n",
      " 1775.1615  1122.2705  1781.4652   905.49    1773.7832  2295.0176\n",
      " 2366.7727  1349.8007  1584.3988  2429.127   1689.5358  1348.2145\n",
      " 2561.652   2120.5208  1245.8477  2240.2117  1299.9618  1826.0444\n",
      " 2372.381   1957.8806  2362.117   2241.7854  2286.6367  1866.3285\n",
      " 1290.9694  1970.2616  2671.3699  2231.6409  2349.0361  1926.1965\n",
      " 1597.6115  1814.8529  1531.5183  1338.407   2398.5122  1886.2268\n",
      " 1735.0256  1863.1796  2107.4524  1500.5007  2785.986   2302.0322\n",
      " 2205.08    2248.8708  2556.1267  2212.5217  1831.5461  2426.5088\n",
      " 1492.066   1791.3877  1448.5591  1235.7523  1647.877   1480.996\n",
      " 2322.015   1899.1892  2045.1909  2277.929   1286.3276  1609.0219\n",
      " 2081.975   2582.5198  1141.2513  2392.894   1826.4847  2396.9988\n",
      " 2654.0352  2215.394   2060.1626  2237.327   1741.278   2347.0276\n",
      " 1782.4469  2526.2778  2643.5706  1438.7397  2248.271   1183.6967\n",
      " 1655.2844  2563.518   1066.4675  2279.4822  2075.0654  1835.2506\n",
      " 1087.9478  1124.8167  1813.1583  2713.1433  2044.6671  1500.0706\n",
      " 1992.3228  1260.6719  1353.9215  1902.1399  2039.6666  2128.258\n",
      " 1981.6143  1935.7168  2407.8213  1745.0408  2385.3984  2460.934\n",
      " 1968.0459  1998.2186  1222.6456  2048.6355  1590.3193  1475.4017\n",
      " 1866.5834  1386.609   2168.8293  2121.1697  1284.8596  1904.5492\n",
      " 2484.1538  2156.1465  2820.6113  2194.2085  2712.759   2015.5259\n",
      " 2530.7317  2276.2007  2148.4358  3048.498   1776.4915  2203.8804\n",
      " 2444.94    2238.7432  2440.4053 ]\n"
     ]
    }
   ],
   "source": [
    "#训练XGboost\n",
    "model_xgb = xgb.XGBRegressor(max_depth=4, learning_rate=0.05, n_estimators=150)\n",
    "model_xgb.fit(X_train_lifetime, y_train_lifetime)\n",
    "print(model_xgb.predict(X_test_lifetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#置换特征重要性\n",
    "perm = PermutationImportance(model_xgb, random_state=1).fit(X_test_lifetime, y_test_lifetime)\n",
    "eli5.show_weights(perm, feature_names=X_test_lifetime.columns.tolist(),top=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:shit]",
   "language": "python",
   "name": "conda-env-shit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
